# Theoretical Foundations: Graph Theory in GNN & MARL

This document outlines the mathematical principles underpinning the Multi-Agent Reinforcement Learning (MARL) algorithms and Graph Neural Networks (GNN) used in this project.

## 1\. åŸºç¡€çŸ©é˜µæ„å»º (The Building Blocks)

åœ¨ GNN å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰çš„ä»£ç å®ç°ä¸­ï¼Œå›¾ç»“æ„ä¸æ˜¯å¯è§†åŒ–çš„å›¾ç‰‡ï¼Œè€Œæ˜¯é€šè¿‡çŸ©é˜µè¿ç®—å®šä¹‰çš„çº¿æ€§ç®—å­ã€‚

### 1.1 é‚»æ¥çŸ©é˜µ (Adjacency Matrix, $A$)

  * **å®šä¹‰**ï¼šæè¿°èŠ‚ç‚¹é—´çš„è¿æ¥å…³ç³»ã€‚$A_{ij}=1$ è¡¨ç¤ºèŠ‚ç‚¹ $i$ ä¸ $j$ ç›¸è¿ï¼Œå¦åˆ™ä¸º $0$ã€‚
  * **GNN ä¸­çš„è§’è‰²**ï¼š**è·¯ç”±æ©ç  (Routing Mask)**ã€‚å®ƒå†³å®šäº†ä¿¡æ¯æµåŠ¨çš„ç‰©ç†è·¯å¾„ã€‚åœ¨çŸ©é˜µä¹˜æ³•ä¸­ï¼Œå®ƒå……å½“äº†â€œé€‰æ‹©å™¨â€ï¼Œå†³å®šå“ªäº›é‚»å±…çš„ç‰¹å¾ä¼šè¢«èšåˆã€‚

#### ğŸ“ Example

Consider a simple 3-agent line topology: `Agent 0 -- Agent 1 -- Agent 2`.

$$
A = \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix}
$$

*Observation: Row 0 has a '1' at column 1, meaning Agent 0 only receives info from Agent 1.*

### 1.2 åº¦çŸ©é˜µ (Degree Matrix, $D$)

  * **å®šä¹‰**ï¼šå¯¹è§’çŸ©é˜µï¼Œå¯¹è§’çº¿å…ƒç´  $D_{ii}$ ä¸ºèŠ‚ç‚¹ $i$ çš„åº¦æ•°ï¼ˆé‚»å±…æ•°é‡ï¼‰ã€‚
  * **GNN ä¸­çš„è§’è‰²**ï¼š**å½’ä¸€åŒ–å™¨ (Normalizer)**ã€‚å¦‚æœä¸å½’ä¸€åŒ–ï¼Œåº¦æ•°å¤§çš„èŠ‚ç‚¹ç‰¹å¾å€¼ä¼šçˆ†ç‚¸ï¼Œåº¦æ•°å°çš„èŠ‚ç‚¹ä¼šè¢«æ·¹æ²¡ã€‚$D$ ç”¨äºå¹³è¡¡è¿™ç§â€œè´«å¯Œå·®è·â€ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ã€‚

#### ğŸ“ Example

For the same line topology above:

  * Agent 0 connects to 1 (Degree = 1)
  * Agent 1 connects to 0 & 2 (Degree = 2)
  * Agent 2 connects to 1 (Degree = 1)

$$
D = \begin{bmatrix}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$

-----

## 2\. ä»£æ•°ä¸è°±å›¾ç†è®º (The Spectral Engine)

è¿™æ˜¯ç†è§£ GNN ä¸ºä»€ä¹ˆæœ‰æ•ˆçš„æ•°å­¦æ ¸å¿ƒã€‚é‡ç‚¹åœ¨äºæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µåŠå…¶ç‰¹å¾å€¼ã€‚

### 2.1 æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ (Laplacian Matrix, $L$)

  * **å®šä¹‰**ï¼š$L = D - A$ã€‚
  * **ç‰©ç†æ„ä¹‰**ï¼šå®ƒæ˜¯å›¾ä¸Šçš„**å·®åˆ†ç®—å­**ã€‚åœ¨ç‰©ç†å­¦ä¸­ï¼Œå®ƒæè¿°äº†æ‰©æ•£è¿‡ç¨‹ï¼ˆå¦‚çƒ­ä¼ å¯¼ï¼‰ï¼›åœ¨æ§åˆ¶ç†è®ºä¸­ï¼Œå®ƒæè¿°äº†è¯¯å·®å¦‚ä½•éšæ—¶é—´æ¶ˆå‡ã€‚

#### ğŸ“ Example

Calculating $L$ for our line graph:

$$
L = \begin{bmatrix}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 1
\end{bmatrix} - \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix} = \begin{bmatrix}
1 & -1 & 0 \\
-1 & 2 & -1 \\
0 & -1 & 1
\end{bmatrix}
$$

### 2.2 ç¬¬äºŒå°ç‰¹å¾å€¼ ($\lambda_2$, Algebraic Connectivity)

è¿™æ˜¯åˆ†æå¤šæ™ºèƒ½ä½“åä½œæ•ˆç‡çš„â€œé»„é‡‘æŒ‡æ ‡â€ã€‚

  * **å®šä¹‰**ï¼šçŸ©é˜µ $L$ çš„ç‰¹å¾å€¼æ’åºä¸º $0 = \lambda_1 \le \lambda_2 \le \dots \le \lambda_n$ã€‚
  * **æ ¸å¿ƒä½œç”¨ (The "Why")**ï¼š
    1.  **æ”¶æ•›é€Ÿåº¦ (Convergence Speed)**ï¼šè¿™æ˜¯ $\lambda_2$ æœ€ä¸»è¦çš„ä½œç”¨ã€‚åœ¨ä¸€è‡´æ€§åè®® ($\dot{x} = -Lx$) ä¸­ï¼Œç³»ç»Ÿè¯¯å·®æŒ‰ $e^{-\lambda_2 t}$ è¡°å‡ã€‚$\lambda_2$ è¶Šå¤§ï¼Œæ™ºèƒ½ä½“è¾¾æˆå…±è¯†è¶Šå¿«ã€‚
    2.  **è¿é€šæ€§ä¸é²æ£’æ€§ (Robustness)**ï¼š$\lambda_2 > 0$ ä¿è¯å›¾æ˜¯è¿é€šçš„ã€‚$\lambda_2$ è¶Šå¤§ï¼Œç³»ç»Ÿè¶Šéš¾è¢«åˆ‡æ–­ï¼ˆæŠ—æ”»å‡»æ€§è¶Šå¼ºï¼‰ã€‚
    3.  **å¹³æ»‘åŠ›åº¦ (Smoothing)**ï¼šåœ¨ GNN ä¸­ï¼Œ$\lambda_2$ è¶Šå¤§ï¼Œå•å±‚å·ç§¯çš„å¹³æ»‘æ•ˆæœè¶Šå¼ºï¼Œæ‰€éœ€çš„ç½‘ç»œå±‚æ•°å¯ä»¥è¶Šæµ…ã€‚

#### ğŸ’» Code Analysis Example

Comparing a **Line Graph** vs. **Complete Graph** (Fully Connected) for 5 agents:

```python
import networkx as nx
import numpy as np

def get_lambda2(G):
    L = nx.laplacian_matrix(G).toarray()
    eigenvalues = np.sort(np.linalg.eigvalsh(L))
    return eigenvalues[1] # The second smallest eigenvalue

# 1. Line Topology (Weak connectivity)
G_line = nx.path_graph(5)
print(f"Line Graph lambda_2: {get_lambda2(G_line):.4f}") 
# Output: ~0.382 (Low value -> Slow convergence)

# 2. Complete Topology (Strong connectivity)
G_complete = nx.complete_graph(5)
print(f"Complete Graph lambda_2: {get_lambda2(G_complete):.4f}") 
# Output: 5.000 (High value -> Fast convergence)
```

-----

## 3\. GNN çš„æ ¸å¿ƒæœºåˆ¶ (Integration with GNN)

GNN å°†ä¸Šè¿°æ•°å­¦ç†è®ºè½¬åŒ–ä¸ºç¥ç»ç½‘ç»œä¸­çš„å±‚ï¼ˆLayerï¼‰ã€‚

### 3.1 å¯¹ç§°å½’ä¸€åŒ–ä¼ æ’­å…¬å¼

ç»å…¸çš„ GCN ä¼ æ’­å…¬å¼å¦‚ä¸‹ï¼š
$$H^{(l+1)} = \sigma \left( \underbrace{\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}}_{\text{Normalized Operator } \hat{A}} H^{(l)} W^{(l)} \right)$$

### 3.2 ä¸ºä»€ä¹ˆè¦è¿™æ ·å½’ä¸€åŒ–ï¼Ÿ($\hat{A} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$)

  * **æ•°å€¼ç¨³å®šæ€§**ï¼šå°†ç‰¹å¾å€¼çº¦æŸåœ¨ $[-1, 1]$ ä¹‹é—´ï¼Œé˜²æ­¢æ·±åº¦ç½‘ç»œä¸­çš„æ•°å€¼çˆ†ç‚¸ã€‚
  * **ç‰©ç†å…¬å¹³æ€§**ï¼šåŒæ—¶å¯¹â€œå‘é€è€…â€å’Œâ€œæ¥æ”¶è€…â€è¿›è¡ŒåŠ æƒè¡°å‡ã€‚æ—¢é˜²æ­¢å¤§åº¦èŠ‚ç‚¹ï¼ˆHubï¼‰ä¸»å¯¼ä¿¡æ¯ï¼Œä¹Ÿé˜²æ­¢å­¤ç«‹èŠ‚ç‚¹è¢«å¿½ç•¥ã€‚
  * **è°±ç†è®ºè¦æ±‚**ï¼šæ„é€ **å®å¯¹ç§°çŸ©é˜µ**ã€‚åªæœ‰å®å¯¹ç§°çŸ©é˜µæ‰æ‹¥æœ‰æ­£äº¤çš„ç‰¹å¾å‘é‡ï¼Œè¿™ä½¿å¾—â€œå›¾å·ç§¯â€åœ¨æ•°å­¦ä¸Šç­‰ä»·äºé¢‘åŸŸæ»¤æ³¢ã€‚

#### ğŸ“ Manual Calculation Example

Let's normalize the connection between Agent 0 and Agent 1.
Assume we add self-loops ($\tilde{A} = A + I$), so degrees become $\tilde{d}_0=2, \tilde{d}_1=3$.
The weight of the message from Node 1 to Node 0 is:

$$
\hat{A}_{0,1} = \frac{1}{\sqrt{\tilde{d}_0} \cdot \sqrt{\tilde{d}_1}} = \frac{1}{\sqrt{2} \cdot \sqrt{3}} \approx \frac{1}{2.45} \approx 0.41
$$

*This $0.41$ factor ensures the signal energy is preserved and balanced.*

### 3.3 çº¿æ€§ç³»ç»Ÿè§†è§’

  * **çº¿æ€§æ‰©æ•£**ï¼šGNN çš„ç‰¹å¾èšåˆæ­¥éª¤ï¼ˆ$\hat{A}H$ï¼‰æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªçº¿æ€§ç¦»æ•£åŠ¨åŠ›ç³»ç»Ÿã€‚å®ƒæ¨¡æ‹Ÿäº†ä¿¡æ¯åœ¨å›¾æ‹“æ‰‘ä¸Šçš„ç‰©ç†æ‰©æ•£è¿‡ç¨‹ã€‚
  * **éçº¿æ€§å¼•å…¥**ï¼šæ¿€æ´»å‡½æ•°ï¼ˆReLUï¼‰æ˜¯å¿…ä¸å¯å°‘çš„ã€‚æ²¡æœ‰å®ƒï¼Œå¤šå±‚ GNN å°±ä¼šé€€åŒ–ä¸ºå•å±‚çš„çº¿æ€§å˜æ¢ã€‚

-----

æ²¡é—®é¢˜ï¼Œè¿™æ˜¯ä¸ºæ‚¨å‡†å¤‡å¥½çš„ä¸­æ–‡ç‰ˆæ–‡æ¡£ï¼Œæ ¼å¼å·²ç»è°ƒæ•´å¥½ï¼Œå¯ä»¥ç›´æ¥å¤åˆ¶åˆ° GitHub çš„ `docs/` æ–‡ä»¶å¤¹æˆ– `README.md` ä¸­ã€‚

***


